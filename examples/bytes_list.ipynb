{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e721fe",
   "metadata": {},
   "source": [
    "# Bytes List\n",
    "\n",
    "This notebook demonstrates the training and evaluation of a neural network designed to convert lists of bytes (bit representations) into their corresponding integer values. \n",
    "\n",
    "The experiment explores two training approaches: supervised learning, where the network learns directly from input-output pairs, and fitness-based learning, where the network is trained using a fitness function based on output accuracy.\n",
    "\n",
    "The notebook covers data generation, neural network construction, training, and performance evaluation, providing insights into how neural networks can learn to interpret binary data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73755b5f",
   "metadata": {},
   "source": [
    "## Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b3f91",
   "metadata": {},
   "source": [
    "### Importing the Neural Network Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf53da",
   "metadata": {},
   "source": [
    "First, we need to import the necessary classes from the `neural_network` library to construct the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from neural_network.layer import HiddenLayer, InputLayer, OutputLayer\n",
    "from neural_network.math.activation_functions import LinearActivation, SigmoidActivation\n",
    "from neural_network.neural_network import NeuralNetwork\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s %(message)s\", datefmt=\"[%d-%m-%Y|%I:%M:%S]\", level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052de14",
   "metadata": {},
   "source": [
    "The following parameters are required to define the architecture of the neural network. The number of inputs is `NUM_BITS`, and the number of outputs is 1.\n",
    "\n",
    "The number of data points to use for training and testing is given by `DATASET_SIZE`. This is split into training and testing datasets to introduce variety in the training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86349de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network parameters\n",
    "HIDDEN_LAYER_SIZES = [3]\n",
    "INPUT_ACTIVATION = LinearActivation\n",
    "HIDDEN_ACTIVATION = SigmoidActivation\n",
    "OUTPUT_ACTIVATION = SigmoidActivation\n",
    "WEIGHTS_RANGE = (-1, 1)\n",
    "BIAS_RANGE = (-0.3, 0.3)\n",
    "LR = 0.5\n",
    "SMOOTHING_ALPHA = 0.25\n",
    "\n",
    "# Dataset parameters\n",
    "DATASET_SIZE = 30000\n",
    "TRAIN_SIZE_RATIO = 0.8\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Bytes lists parameters\n",
    "NUM_BITS = 8\n",
    "IN_LIMS = [0, 255]\n",
    "OUT_LIMS = [0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363ccb3",
   "metadata": {},
   "source": [
    "### Creating Methods to Generate Training Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fe3a8",
   "metadata": {},
   "source": [
    "We will be using 8-bit numbers to train the neural network.\n",
    "The following functions will allow us to convert between between integers and bytes lists.\n",
    "We can use those functions to create the training and testing datasets.\n",
    "We will select random numbers and train the neural network with the corresponding byte lists and expected outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_byte_list(num: int) -> list[int]:\n",
    "    \"\"\"Convert a number to a list of bits.\n",
    "\n",
    "    :param int num:\n",
    "        Number to convert.\n",
    "    :return list[int]:\n",
    "        Number represented as list of bits.\n",
    "    \"\"\"\n",
    "    _num_bin = bin(num)\n",
    "    _num_bytes = _num_bin[2:]\n",
    "    _padding = [0] * (NUM_BITS - len(_num_bytes))\n",
    "    return _padding + [int(b) for b in _num_bytes]\n",
    "\n",
    "\n",
    "def map_val(x: float, in_min: float, in_max: float, out_min: float, out_max: float) -> float:\n",
    "    \"\"\"Map a value from an input range to an output range.\n",
    "\n",
    "    :param float x:\n",
    "        Number to map to new range.\n",
    "    :param float in_min:\n",
    "        Lower bound of original range.\n",
    "    :param float in_max:\n",
    "        Upper bound of original range.\n",
    "    :param float out_min:\n",
    "        Lower bound of new range.\n",
    "    :param float out_max:\n",
    "        Upper bound of new range.\n",
    "    :return float:\n",
    "        Number mapped to new range.\n",
    "    \"\"\"\n",
    "    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "\n",
    "\n",
    "def training_data_from_num(num: int) -> tuple[list[int], float]:\n",
    "    \"\"\"Generate byte list and mapped number from a number to use in training.\n",
    "\n",
    "    :param int num:\n",
    "        Number to use for training data.\n",
    "    :return tuple[list[int], float]:\n",
    "        Input and expected output.\n",
    "    \"\"\"\n",
    "    _byte_list = np.array(num_to_byte_list(num))\n",
    "    _mapped_num = map_val(num, IN_LIMS[0], IN_LIMS[1], OUT_LIMS[0], OUT_LIMS[1])\n",
    "    return (_byte_list, _mapped_num)\n",
    "\n",
    "\n",
    "def split_data(\n",
    "    data: list[tuple[list[int], float]], train_size_ratio: float = TRAIN_SIZE_RATIO\n",
    ") -> tuple[list[tuple[list[int], float]], list[tuple[list[int], float]]]:\n",
    "    \"\"\"Split the dataset into training and testing sets.\n",
    "\n",
    "    :param list[tuple[list[int], float]] data:\n",
    "        The dataset to split.\n",
    "    :param float train_size_ratio:\n",
    "        The proportion of the dataset to include in the training split.\n",
    "    :return tuple[list[tuple[list[int], float]], list[tuple[list[int], float]]]:\n",
    "        Training and testing datasets.\n",
    "    \"\"\"\n",
    "    train_size = int(len(data) * train_size_ratio)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def calculate_errors(expected_outputs: np.ndarray, actual_outputs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculate the error between expected and actual outputs.\n",
    "\n",
    "    :param np.ndarray expected_outputs:\n",
    "        The expected output values.\n",
    "    :param np.ndarray actual_outputs:\n",
    "        The actual output values.\n",
    "    :return np.ndarray:\n",
    "        The calculated errors.\n",
    "    \"\"\"\n",
    "    errors = expected_outputs - np.array(actual_outputs)\n",
    "    return map_val(errors, OUT_LIMS[0], OUT_LIMS[1], IN_LIMS[0], IN_LIMS[1])\n",
    "\n",
    "\n",
    "def calculate_percentage_error(errors: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the percentage error from a list of errors.\n",
    "\n",
    "    :param np.ndarray errors:\n",
    "        The list of errors.\n",
    "    :return float:\n",
    "        The average error as a percentage.\n",
    "    \"\"\"\n",
    "    avg_error = np.average(errors)\n",
    "    return np.abs(avg_error) / IN_LIMS[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58a154",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2d6b1",
   "metadata": {},
   "source": [
    "The supervised learning approach uses expected outputs against given inputs to backpropagate errors.\n",
    "In the fitness-based approach, we need to calculate the fitness value for each output against given inputs, and use that to calculate the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised training\n",
    "def generate_supervised_training_data(dataset_size: int) -> list[tuple[list[int], float]]:\n",
    "    \"\"\"Generate supervised training data for the neural network.\n",
    "\n",
    "    :param int dataset_size:\n",
    "        Number of samples to generate.\n",
    "    :return list[tuple[list[int], float]]:\n",
    "        Input and expected output pairs.\n",
    "    \"\"\"\n",
    "    random_num = rng.integers(low=IN_LIMS[0], high=(IN_LIMS[1] + 1), size=dataset_size)\n",
    "    return [training_data_from_num(num) for num in random_num]\n",
    "\n",
    "\n",
    "# Fitness training\n",
    "def calculate_fitness(expected_output: float, nn_output: float) -> float:\n",
    "    \"\"\"Calculate fitness based on the accuracy of the neural network's output.\n",
    "\n",
    "    :param float expected_output:\n",
    "        The correct output value.\n",
    "    :param float nn_output:\n",
    "        The neural network's predicted output.\n",
    "    :return float:\n",
    "        A fitness value where higher is better.\n",
    "    \"\"\"\n",
    "    error = abs(expected_output - nn_output)\n",
    "    normalized_error = error / (OUT_LIMS[1] - OUT_LIMS[0])\n",
    "    return np.exp(-normalized_error * 5)\n",
    "\n",
    "\n",
    "def generate_fitness_training_data(dataset_size: int, nn: NeuralNetwork) -> list[tuple[list[int], float]]:\n",
    "    \"\"\"Generate fitness training data for the neural network.\n",
    "\n",
    "    :param int dataset_size:\n",
    "        Number of samples to generate.\n",
    "    :param NeuralNetwork nn:\n",
    "        Neural network to evaluate outputs.\n",
    "    :return list[tuple[list[int], float]]:\n",
    "        Input and fitness values.\n",
    "    \"\"\"\n",
    "    data = generate_supervised_training_data(dataset_size)\n",
    "    nn_outputs = [nn.feedforward(input_data) for input_data, _ in data]\n",
    "    return [\n",
    "        (input_data, calculate_fitness(expected_output, nn_output))\n",
    "        for (input_data, expected_output), nn_output in zip(data, nn_outputs, strict=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab1e44",
   "metadata": {},
   "source": [
    "### Neural Network Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68993a9b",
   "metadata": {},
   "source": [
    "The following functions are used to create and test neural networks using the parameters defined earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7da51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(\n",
    "    input_size: int = NUM_BITS,\n",
    "    hidden_layer_sizes: list[int] = HIDDEN_LAYER_SIZES,\n",
    "    input_activation: type = INPUT_ACTIVATION,\n",
    "    hidden_activation: type = HIDDEN_ACTIVATION,\n",
    "    output_activation: type = OUTPUT_ACTIVATION,\n",
    "    weights_range: tuple[float, float] = WEIGHTS_RANGE,\n",
    "    bias_range: tuple[float, float] = BIAS_RANGE,\n",
    "    lr: float = LR,\n",
    ") -> NeuralNetwork:\n",
    "    \"\"\"Create a neural network with specified parameters.\n",
    "\n",
    "    :param int input_size:\n",
    "        Number of input nodes.\n",
    "    :param list[int] hidden_layer_sizes:\n",
    "        Sizes of hidden layers.\n",
    "    :param type input_activation:\n",
    "        Activation function for input layer.\n",
    "    :param type hidden_activation:\n",
    "        Activation function for hidden layers.\n",
    "    :param type output_activation:\n",
    "        Activation function for output layer.\n",
    "    :param tuple[float, float] weights_range:\n",
    "        Range for initializing weights.\n",
    "    :param tuple[float, float] bias_range:\n",
    "        Range for initializing biases.\n",
    "    :param float lr:\n",
    "        Learning rate.\n",
    "    :return NeuralNetwork:\n",
    "        Constructed neural network.\n",
    "    \"\"\"\n",
    "    input_layer = InputLayer(size=input_size, activation=input_activation)\n",
    "    hidden_layers = [\n",
    "        HiddenLayer(size=size, activation=hidden_activation, weights_range=weights_range, bias_range=bias_range)\n",
    "        for size in hidden_layer_sizes\n",
    "    ]\n",
    "    output_layer = OutputLayer(size=1, activation=output_activation, weights_range=weights_range, bias_range=bias_range)\n",
    "\n",
    "    return NeuralNetwork.from_layers(layers=[input_layer, *hidden_layers, output_layer], lr=lr)\n",
    "\n",
    "\n",
    "def evaluate_nn(nn: NeuralNetwork, data: list[tuple[list[int], float]]) -> tuple[float, float]:\n",
    "    \"\"\"Evaluate the neural network on a dataset.\n",
    "\n",
    "    :param NeuralNetwork nn:\n",
    "        The neural network to evaluate.\n",
    "    :param list[tuple[list[int], float]] data:\n",
    "        The dataset to evaluate on.\n",
    "    :return tuple[np.ndarray, float]:\n",
    "        List of errors and average error as a percentage.\n",
    "    \"\"\"\n",
    "    dataset_size = len(data)\n",
    "    outputs = []\n",
    "    for i in range(dataset_size):\n",
    "        inputs = data[i][0]\n",
    "        output = nn.feedforward(inputs)[0]\n",
    "        outputs.append(output)\n",
    "\n",
    "    errors = calculate_errors(\n",
    "        expected_outputs=np.array([data[i][1] for i in range(dataset_size)]), actual_outputs=np.array(outputs)\n",
    "    )\n",
    "    percentage_error = calculate_percentage_error(errors)\n",
    "    return errors, percentage_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cdc78e",
   "metadata": {},
   "source": [
    "### Running the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a8c4e",
   "metadata": {},
   "source": [
    "Now we can run the training algorithm and test the neural network to evaluate its accuracy.\n",
    "First, we will use the supervised learning approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35fe0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-06-2025|01:45:27] Creating neural network for supervised training...\n",
      "[05-06-2025|01:45:27] Generating supervised training data with 30000 data points...\n",
      "[05-06-2025|01:45:27] Training neural network with 24000 data points for 20 epochs...\n",
      "[05-06-2025|01:45:56] Testing neural network with 6000 data points...\n",
      "[05-06-2025|01:45:56] Average error: 0.4527\n",
      "[05-06-2025|01:45:56] Supervised training percentage error: 0.1775%\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Creating neural network for supervised training...\")\n",
    "nn_supervised = create_nn()\n",
    "logger.info(\"Generating supervised training data with %s data points...\", DATASET_SIZE)\n",
    "data_supervised = generate_supervised_training_data(DATASET_SIZE)\n",
    "training_data_supervised, testing_data_supervised = split_data(data_supervised)\n",
    "logger.info(\"Training neural network with %s data points for %s epochs...\", len(training_data_supervised), NUM_EPOCHS)\n",
    "nn_supervised.run_supervised_training(\n",
    "    inputs=[input_data for input_data, _ in training_data_supervised],\n",
    "    expected_outputs=[expected_output for _, expected_output in training_data_supervised],\n",
    "    epochs=NUM_EPOCHS,\n",
    ")\n",
    "\n",
    "logger.info(\"Testing neural network with %s data points...\", len(testing_data_supervised))\n",
    "errors, percentage_error = evaluate_nn(nn_supervised, testing_data_supervised)\n",
    "avg_error = np.average(errors)\n",
    "logger.info(\"Average error: %.4f\", avg_error)\n",
    "logger.info(\"Supervised training percentage error: %.4f%%\", percentage_error * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11e15b",
   "metadata": {},
   "source": [
    "Now for the fitness-based approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c39414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-06-2025|01:45:56] Creating neural network for fitness training...\n",
      "[05-06-2025|01:45:56] Generating fitness training data with 30000 data points...\n",
      "[05-06-2025|01:45:57] Training neural network with 24000 data points...\n",
      "[05-06-2025|01:46:28] Testing neural network with 6000 data points...\n",
      "[05-06-2025|01:46:29] Average error: 1.5349\n",
      "[05-06-2025|01:46:29] Fitness training percentage error: 0.6019%\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Creating neural network for fitness training...\")\n",
    "nn_fitness = create_nn()\n",
    "logger.info(\"Generating fitness training data with %s data points...\", DATASET_SIZE)\n",
    "data_fitness = generate_fitness_training_data(DATASET_SIZE, nn_fitness)\n",
    "training_data_fitness, testing_data_fitness = split_data(data_fitness)\n",
    "logger.info(\"Training neural network with %s data points...\", len(training_data_fitness))\n",
    "nn_fitness.run_fitness_training(\n",
    "    inputs=[input_data for input_data, _ in training_data_fitness],\n",
    "    fitnesses=[fitness for _, fitness in training_data_fitness],\n",
    "    epochs=NUM_EPOCHS,\n",
    ")\n",
    "\n",
    "logger.info(\"Testing neural network with %s data points...\", len(testing_data_fitness))\n",
    "errors, percentage_error = evaluate_nn(nn_fitness, testing_data_fitness)\n",
    "avg_error = np.average(errors)\n",
    "logger.info(\"Average error: %.4f\", avg_error)\n",
    "logger.info(\"Fitness training percentage error: %.4f%%\", percentage_error * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network-u-ZqOggc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
