{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e721fe",
   "metadata": {},
   "source": [
    "# Bytes List\n",
    "\n",
    "This notebook demonstrates the training and evaluation of a neural network designed to convert lists of bytes (bit representations) into their corresponding integer values. \n",
    "\n",
    "The experiment explores two training approaches: supervised learning, where the network learns directly from input-output pairs, and fitness-based learning, where the network is trained using a fitness function based on output accuracy.\n",
    "\n",
    "The notebook covers data generation, neural network construction, training, and performance evaluation, providing insights into how neural networks can learn to interpret binary data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73755b5f",
   "metadata": {},
   "source": [
    "## Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b3f91",
   "metadata": {},
   "source": [
    "### Importing the Neural Network Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf53da",
   "metadata": {},
   "source": [
    "First, we need to import the necessary classes from the `neural_network` library to construct the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from neural_network.layer import HiddenLayer, InputLayer, OutputLayer\n",
    "from neural_network.math.activation_functions import LinearActivation, SigmoidActivation\n",
    "from neural_network.neural_network import NeuralNetwork\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa87b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlushedConsoleHandler(logging.StreamHandler):\n",
    "    def emit(self, record: logging.LogRecord) -> None:\n",
    "        msg = self.format(record)\n",
    "        sys.stdout.write('\\r' + msg)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "formatter = logging.Formatter('[%(asctime)s] %(message)s', datefmt='%d-%m-%Y | %H:%M:%S')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]\n",
    "\n",
    "flushed_logger = logging.getLogger('flushed_logger')\n",
    "flushed_logger.setLevel(logging.INFO)\n",
    "handler = FlushedConsoleHandler()\n",
    "handler.setFormatter(formatter)\n",
    "flushed_logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052de14",
   "metadata": {},
   "source": [
    "The following parameters are required to define the architecture of the neural network. The number of inputs is `NUM_BITS`, and the number of outputs is 1.\n",
    "\n",
    "The number of data points to use for training and testing is given by `DATASET_SIZE`. This is split into training and testing datasets to introduce variety in the training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86349de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network parameters\n",
    "HIDDEN_LAYER_SIZES = [3]\n",
    "INPUT_ACTIVATION = LinearActivation\n",
    "HIDDEN_ACTIVATION = SigmoidActivation\n",
    "OUTPUT_ACTIVATION = SigmoidActivation\n",
    "WEIGHTS_RANGE = (-1, 1)\n",
    "BIAS_RANGE = (-0.3, 0.3)\n",
    "LR = 0.1\n",
    "SMOOTHING_ALPHA = 0.25\n",
    "\n",
    "# Dataset parameters\n",
    "DATASET_SIZE = 30000\n",
    "TRAIN_SIZE_RATIO = 0.8\n",
    "EPOCHS = 5\n",
    "\n",
    "# Bytes lists parameters\n",
    "NUM_BITS = 8\n",
    "IN_LIMS = [0, 255]\n",
    "OUT_LIMS = [0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363ccb3",
   "metadata": {},
   "source": [
    "### Creating Methods to Generate Training Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fe3a8",
   "metadata": {},
   "source": [
    "We will be using 8-bit numbers to train the neural network.\n",
    "The following functions will allow us to convert between between integers and bytes lists.\n",
    "We can use those functions to create the training and testing datasets.\n",
    "We will select random numbers and train the neural network with the corresponding byte lists and expected outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b9eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_byte_list(num: int) -> list[int]:\n",
    "    \"\"\"\n",
    "    Convert a number to a list of bits.\n",
    "\n",
    "    Parameters:\n",
    "        num (int): Number to convert\n",
    "\n",
    "    Returns:\n",
    "        byte_list (list[int]): Number represented as list of bits\n",
    "    \"\"\"\n",
    "    _num_bin = bin(num)\n",
    "    _num_bytes = _num_bin[2:]\n",
    "    _padding = [0] * (NUM_BITS - len(_num_bytes))\n",
    "    return _padding + [int(b) for b in _num_bytes]\n",
    "\n",
    "\n",
    "def map_val(x: float, in_min: float, in_max: float, out_min: float, out_max: float) -> float:\n",
    "    \"\"\"\n",
    "    Map a value from an input range to an output range.\n",
    "\n",
    "    Parameters:\n",
    "        x (float): Number to map to new range\n",
    "        in_min (float): Lower bound of original range\n",
    "        in_max (float): Upper bound of original range\n",
    "        out_min (float): Lower bound of new range\n",
    "        out_max (float): Upper bound of new range\n",
    "\n",
    "    Returns:\n",
    "        y (float): Number mapped to new range\n",
    "    \"\"\"\n",
    "    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "\n",
    "def training_data_from_num(num: int) -> tuple[list[int], float]:\n",
    "    \"\"\"\n",
    "    Generate byte list and mapped number from a number to use in training.\n",
    "\n",
    "    Parameters:\n",
    "        num (int): Number to use for training data\n",
    "\n",
    "    Returns:\n",
    "        training_data (tuple[list[int], float]): Input and expected output\n",
    "    \"\"\"\n",
    "    _byte_list = np.array(num_to_byte_list(num))\n",
    "    _mapped_num = map_val(num, IN_LIMS[0], IN_LIMS[1], OUT_LIMS[0], OUT_LIMS[1])\n",
    "    return (_byte_list, _mapped_num)\n",
    "\n",
    "\n",
    "def split_data(\n",
    "    data: list[tuple[list[int], float]], train_size_ratio: float = TRAIN_SIZE_RATIO\n",
    ") -> tuple[list[tuple[list[int], float]], list[tuple[list[int], float]]]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        data (list[tuple[list[int], float]]): The dataset to split.\n",
    "        train_size_ratio (float): The proportion of the dataset to include in the training split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training and testing datasets.\n",
    "    \"\"\"\n",
    "    train_size = int(len(data) * train_size_ratio)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:]\n",
    "    return train_data, test_data\n",
    "\n",
    "def calculate_errors(expected_outputs: np.ndarray, actual_outputs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the error between expected and actual outputs.\n",
    "\n",
    "    Parameters:\n",
    "        expected_outputs (np.ndarray): The expected output values.\n",
    "        actual_outputs (np.ndarray): The actual output values.\n",
    "\n",
    "    Returns:\n",
    "        errors (np.ndarray): The calculated errors.\n",
    "    \"\"\"\n",
    "    errors = expected_outputs - np.array(actual_outputs)\n",
    "    return map_val(errors, OUT_LIMS[0], OUT_LIMS[1], IN_LIMS[0], IN_LIMS[1])\n",
    "\n",
    "\n",
    "def calculate_percentage_error(errors: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the percentage error from a list of errors.\n",
    "\n",
    "    Parameters:\n",
    "        errors (np.ndarray): The list of errors.\n",
    "\n",
    "    Returns:\n",
    "        percentage_error (float): The average error as a percentage.\n",
    "    \"\"\"\n",
    "    avg_error = np.average(errors)\n",
    "    return np.abs(avg_error) / IN_LIMS[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab1e44",
   "metadata": {},
   "source": [
    "### Neural Network Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68993a9b",
   "metadata": {},
   "source": [
    "The following functions are used to create and test neural networks using the parameters defined earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7da51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(\n",
    "    input_size: int = NUM_BITS,\n",
    "    hidden_layer_sizes: list[int] = HIDDEN_LAYER_SIZES,\n",
    "    input_activation: type = INPUT_ACTIVATION,\n",
    "    hidden_activation: type = HIDDEN_ACTIVATION,\n",
    "    output_activation: type = OUTPUT_ACTIVATION,\n",
    "    weights_range: tuple[float, float] = WEIGHTS_RANGE,\n",
    "    bias_range: tuple[float, float] = BIAS_RANGE,\n",
    "    lr: float = LR,\n",
    ") -> NeuralNetwork:\n",
    "    \"\"\"Create a neural network with specified parameters.\"\"\"\n",
    "    input_layer = InputLayer(size=input_size, activation=input_activation)\n",
    "    hidden_layers = [\n",
    "        HiddenLayer(size=size, activation=hidden_activation, weights_range=weights_range, bias_range=bias_range)\n",
    "        for size in hidden_layer_sizes\n",
    "    ]\n",
    "    output_layer = OutputLayer(size=1, activation=output_activation, weights_range=weights_range, bias_range=bias_range)\n",
    "\n",
    "    return NeuralNetwork.from_layers(layers=[input_layer, *hidden_layers, output_layer], lr=lr)\n",
    "\n",
    "def evaluate_nn(\n",
    "    nn: NeuralNetwork, data: list[tuple[list[int], float]]\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the neural network on a dataset.\n",
    "\n",
    "    Parameters:\n",
    "        nn (NeuralNetwork): The neural network to evaluate.\n",
    "        data (list[tuple[list[int], float]]): The dataset to evaluate on.\n",
    "\n",
    "    Returns:\n",
    "        errors (np.ndarray): The list of errors.\n",
    "        percentage_error (float): The average error as a percentage.\n",
    "    \"\"\"\n",
    "    dataset_size = len(data)\n",
    "    outputs = []\n",
    "    for i in range(dataset_size):\n",
    "        inputs = data[i][0]\n",
    "        output = nn.feedforward(inputs)[0]\n",
    "        outputs.append(output)\n",
    "\n",
    "    errors = calculate_errors(\n",
    "        expected_outputs=np.array([data[i][1] for i in range(dataset_size)]), actual_outputs=np.array(outputs)\n",
    "    )\n",
    "    percentage_error = calculate_percentage_error(errors)\n",
    "    return errors, percentage_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58a154",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2d6b1",
   "metadata": {},
   "source": [
    "The supervised learning approach uses expected outputs against given inputs to backpropagate errors.\n",
    "In the fitness-based approach, we need to calculate the fitness value for each output against given inputs, and use that to calculate the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870bdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised training\n",
    "def generate_supervised_training_data(dataset_size: int) -> list[tuple[list[int], float]]:\n",
    "    \"\"\"\n",
    "    Generate supervised training data for the neural network.\n",
    "\n",
    "    Returns:\n",
    "        training_data (tuple[list[list[int]], list[float]]): Input and expected output pairs\n",
    "    \"\"\"\n",
    "    random_num = rng.integers(low=IN_LIMS[0], high=(IN_LIMS[1] + 1), size=dataset_size)\n",
    "    return [training_data_from_num(num) for num in random_num]\n",
    "\n",
    "\n",
    "# Fitness training\n",
    "def calculate_fitness(expected_output: float, nn_output: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate fitness based on the accuracy of the neural network's output.\n",
    "\n",
    "    Parameters:\n",
    "        expected_output (float): The correct output value.\n",
    "        nn_output (float): The neural network's predicted output.\n",
    "\n",
    "    Returns:\n",
    "        fitness (float): A fitness value where higher is better.\n",
    "    \"\"\"\n",
    "    error = abs(expected_output - nn_output)\n",
    "    normalized_error = error / (OUT_LIMS[1] - OUT_LIMS[0])\n",
    "    return np.exp(-normalized_error * 5)\n",
    "\n",
    "\n",
    "def generate_fitness_training_data(dataset_size: int, nn: NeuralNetwork) -> list[tuple[list[int], float]]:\n",
    "    \"\"\"\n",
    "    Generate fitness training data for the neural network.\n",
    "\n",
    "    Returns:\n",
    "        training_data (tuple[list[list[int]], list[float]]): Input and fitness values\n",
    "    \"\"\"\n",
    "    data = generate_supervised_training_data(dataset_size)\n",
    "    nn_outputs = [nn.feedforward(input_data) for input_data, _ in data]\n",
    "    return [\n",
    "        (input_data, calculate_fitness(expected_output, nn_output))\n",
    "        for (input_data, expected_output), nn_output in zip(data, nn_outputs, strict=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cdc78e",
   "metadata": {},
   "source": [
    "### Running the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a8c4e",
   "metadata": {},
   "source": [
    "Now we can run the training algorithm and test the neural network to evaluate its accuracy.\n",
    "First, we will use the supervised learning approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35fe0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-06-2025 | 00:12:30] Creating neural network for supervised training...\n",
      "[05-06-2025 | 00:12:30] Generating supervised training data...\n",
      "[05-06-2025 | 00:12:30] Training neural network with supervised learning...\n",
      "[05-06-2025 | 00:12:38] Testing neural network with supervised learning...\n",
      "[05-06-2025 | 00:12:38] Supervised training percentage error: 0.0001%\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Creating neural network for supervised training...\")\n",
    "nn_supervised = create_nn()\n",
    "logger.info(\"Generating supervised training data...\")\n",
    "data_supervised = generate_supervised_training_data(DATASET_SIZE)\n",
    "training_data_supervised, testing_data_supervised = split_data(data_supervised)\n",
    "logger.info(\"Training neural network with supervised learning...\")\n",
    "nn_supervised.run_supervised_training(\n",
    "    inputs=[input_data for input_data, _ in training_data_supervised],\n",
    "    expected_outputs=[expected_output for _, expected_output in training_data_supervised],\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "logger.info(\"Testing neural network with supervised learning...\")\n",
    "_, percentage_error = evaluate_nn(nn_supervised, testing_data_supervised)\n",
    "msg = f\"Supervised training percentage error: {percentage_error:.4f}%\"\n",
    "logger.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11e15b",
   "metadata": {},
   "source": [
    "Now for the fitness-based approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c39414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-06-2025 | 00:12:38] Creating neural network for fitness training...\n",
      "[05-06-2025 | 00:12:38] Generating fitness training data...\n",
      "[05-06-2025 | 00:12:39] Training neural network with fitness-based learning...\n",
      "[05-06-2025 | 00:12:47] Testing neural network with fitness-based learning...\n",
      "[05-06-2025 | 00:12:47] Fitness training percentage error: 0.0358%\n"
     ]
    }
   ],
   "source": [
    "# Fitness training\n",
    "logger.info(\"Creating neural network for fitness training...\")\n",
    "nn_fitness = create_nn()\n",
    "logger.info(\"Generating fitness training data...\")\n",
    "data_fitness = generate_fitness_training_data(DATASET_SIZE, nn_fitness)\n",
    "training_data_fitness, testing_data_fitness = split_data(data_fitness)\n",
    "logger.info(\"Training neural network with fitness-based learning...\")\n",
    "nn_fitness.run_fitness_training(\n",
    "    inputs=[input_data for input_data, _ in training_data_fitness],\n",
    "    fitnesses=[fitness for _, fitness in training_data_fitness],\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "# Testing\n",
    "logger.info(\"Testing neural network with fitness-based learning...\")\n",
    "_, percentage_error = evaluate_nn(nn_fitness, testing_data_fitness)\n",
    "msg = f\"Fitness training percentage error: {percentage_error:.4f}%\"\n",
    "logger.info(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network-u-ZqOggc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
